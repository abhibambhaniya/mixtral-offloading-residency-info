{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 00:58:59 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   31C    P0             113W / 700W |  12195MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    471552      C   /scratch/592241/moe_offload/bin/python    12166MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://people.eecs.berkeley.edu/~hendrycks/data.tar -O mmlu.tar\n",
    "# !tar -xf mmlu.tar -C mmlu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload the imported modules (e.g. get_decode_model_characterstics) every time you execute the jupyter cells, so that you don't need to restart the notebook after updating the source codes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mhqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/592241/moe_offload/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "script_dir = os.getcwd()\n",
    "module_path = script_dir\n",
    "for _ in range(1):\n",
    "    module_path = os.path.abspath(os.path.join(module_path, '../'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.insert(0,module_path)\n",
    "        \n",
    "sys.path.append(\"mixtral-offloading\")\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from hqq.core.quantize import BaseQuantizeConfig\n",
    "from huggingface_hub import snapshot_download\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import trange\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers.utils import logging as hf_logging\n",
    "import time\n",
    "import gc\n",
    "from src.build_model import OffloadConfig, QuantConfig, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo1\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(quantized_model_name)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n",
    "offload_per_layer = 4\n",
    "# offload_per_layer = 5\n",
    "###############################################################\n",
    "\n",
    "num_experts = config.num_local_experts\n",
    "\n",
    "offload_config = OffloadConfig(\n",
    "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
    "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
    "    buffer_size=4,\n",
    "    offload_per_layer=offload_per_layer,\n",
    ")\n",
    "\n",
    "\n",
    "attn_config = BaseQuantizeConfig(\n",
    "    nbits=4,\n",
    "    group_size=64,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
    "\n",
    "\n",
    "ffn_config = BaseQuantizeConfig(\n",
    "    nbits=2,\n",
    "    group_size=16,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
    "\n",
    "\n",
    "# del model\n",
    "\n",
    "gc.collect\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/592241/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"BIASING\",\n",
    "    routing_threshold=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.118 sec, avg expert load reduced: 946.25, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.123 sec, avg expert load reduced: 3035.925925925926, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.356 sec, avg expert load reduced: 5538.519736842105, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.343 sec, avg expert load reduced: 7703.75, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.199 sec, avg expert load reduced: 10631.06037735849, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.260 sec, avg expert load reduced: 13906.506944444445, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.331 sec, avg expert load reduced: 15903.74, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.580 sec, avg expert load reduced: 17635.3, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.357 sec, avg expert load reduced: 19432.49, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.300 sec, avg expert load reduced: 21861.85549132948, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.257 sec, avg expert load reduced: 24210.343137254902, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.142 sec, avg expert load reduced: 25938.96, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.056 sec, avg expert load reduced: 28870.251063829786, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.388 sec, avg expert load reduced: 31916.63157894737, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.212 sec, avg expert load reduced: 34121.43448275862, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.320 sec, avg expert load reduced: 38397.95502645503, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.408 sec, avg expert load reduced: 42549.166666666664, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.199 sec, avg expert load reduced: 44523.02, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.305 sec, avg expert load reduced: 48058.709677419356, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.283 sec, avg expert load reduced: 52487.04433497537, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.663 sec, avg expert load reduced: 55031.04, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.453 sec, avg expert load reduced: 57242.01818181818, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.146 sec, avg expert load reduced: 60310.818181818184, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.230 sec, avg expert load reduced: 63663.51813471503, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.141 sec, avg expert load reduced: 68736.47948717949, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.292 sec, avg expert load reduced: 74408.17037037037, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.158 sec, avg expert load reduced: 78784.53361344538, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.325 sec, avg expert load reduced: 82239.54304635762, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.273 sec, avg expert load reduced: 88297.95596330275, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.599 sec, avg expert load reduced: 94840.94907407407, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.477 sec, avg expert load reduced: 98374.92156862745, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.224 sec, avg expert load reduced: 102037.57383966245, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.082 sec, avg expert load reduced: 105942.31838565023, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.120 sec, avg expert load reduced: 108892.97709923664, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.422 sec, avg expert load reduced: 110960.28099173553, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.166 sec, avg expert load reduced: 112871.0925925926, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.206 sec, avg expert load reduced: 115081.67484662577, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.431 sec, avg expert load reduced: 117451.61607142857, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.049 sec, avg expert load reduced: 119355.54368932039, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.182 sec, avg expert load reduced: 122069.07692307692, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.125 sec, avg expert load reduced: 124779.89, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.080 sec, avg expert load reduced: 131700.3933588761, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.249 sec, avg expert load reduced: 140829.70520231215, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.428 sec, avg expert load reduced: 152149.4, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.380 sec, avg expert load reduced: 162734.21241830065, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.096 sec, avg expert load reduced: 167797.10932475884, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.308 sec, avg expert load reduced: 173156.07098765433, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.479 sec, avg expert load reduced: 178308.56737588652, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.430 sec, avg expert load reduced: 194465.9882659713, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.929 sec, avg expert load reduced: 210618.4375, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.339 sec, avg expert load reduced: 218274.03921568627, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.169 sec, avg expert load reduced: 224510.85454545455, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:1.964 sec, avg expert load reduced: 227484.79591836734, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.195 sec, avg expert load reduced: 231238.92039800994, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.182 sec, avg expert load reduced: 233777.02, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.107 sec, avg expert load reduced: 236022.01204819276, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.030 sec, avg expert load reduced: 238891.8304093567, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./biasing_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Ref: https://wandb.ai/byyoung3/ml-news/reports/Testing-Mixtral-8x7B-with-MMLU-and-W-B---Vmlldzo2MjI0ODAz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/585587/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"THRESHOLDING\",\n",
    "    routing_threshold=0.075\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.154 sec, avg expert load reduced: 599.33, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.153 sec, avg expert load reduced: 1882.8592592592593, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.394 sec, avg expert load reduced: 3385.125, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.376 sec, avg expert load reduced: 4655.49, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.227 sec, avg expert load reduced: 6464.0037735849055, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.286 sec, avg expert load reduced: 8545.583333333334, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.351 sec, avg expert load reduced: 9841.8, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.601 sec, avg expert load reduced: 10911.43, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.380 sec, avg expert load reduced: 11974.73, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.319 sec, avg expert load reduced: 13425.71098265896, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.279 sec, avg expert load reduced: 14842.362745098038, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.156 sec, avg expert load reduced: 15900.2, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.071 sec, avg expert load reduced: 17734.73191489362, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.409 sec, avg expert load reduced: 19684.36842105263, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.227 sec, avg expert load reduced: 21048.344827586207, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.336 sec, avg expert load reduced: 23772.53439153439, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.426 sec, avg expert load reduced: 26448.73015873016, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.211 sec, avg expert load reduced: 27662.6, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.321 sec, avg expert load reduced: 29839.60322580645, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.301 sec, avg expert load reduced: 32580.935960591134, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.679 sec, avg expert load reduced: 34170.55, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.468 sec, avg expert load reduced: 35511.07878787879, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.160 sec, avg expert load reduced: 37325.32828282828, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.250 sec, avg expert load reduced: 39283.678756476686, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.157 sec, avg expert load reduced: 42194.015384615384, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.312 sec, avg expert load reduced: 45503.32962962963, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.174 sec, avg expert load reduced: 48164.6512605042, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.347 sec, avg expert load reduced: 50177.30463576159, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.291 sec, avg expert load reduced: 53805.7504587156, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.609 sec, avg expert load reduced: 57760.75925925926, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.490 sec, avg expert load reduced: 59878.936274509804, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.240 sec, avg expert load reduced: 61998.10548523207, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.092 sec, avg expert load reduced: 64366.29596412556, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.131 sec, avg expert load reduced: 66218.29770992366, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.436 sec, avg expert load reduced: 67526.17355371901, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.179 sec, avg expert load reduced: 68766.31481481482, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.219 sec, avg expert load reduced: 70162.69938650307, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.446 sec, avg expert load reduced: 71575.99107142857, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.062 sec, avg expert load reduced: 72715.7572815534, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.193 sec, avg expert load reduced: 74498.70512820513, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.139 sec, avg expert load reduced: 76275.95, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.092 sec, avg expert load reduced: 80810.83269476373, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.271 sec, avg expert load reduced: 86648.80635838151, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.449 sec, avg expert load reduced: 93716.85363128492, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.400 sec, avg expert load reduced: 100324.46078431372, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.113 sec, avg expert load reduced: 103525.31832797428, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.323 sec, avg expert load reduced: 106870.41975308642, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.499 sec, avg expert load reduced: 110083.92907801419, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.444 sec, avg expert load reduced: 119364.43350717079, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.943 sec, avg expert load reduced: 128583.79779411765, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.364 sec, avg expert load reduced: 133058.27614379086, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.189 sec, avg expert load reduced: 136668.57272727272, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:1.978 sec, avg expert load reduced: 138410.77142857143, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.215 sec, avg expert load reduced: 140621.62189054728, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.200 sec, avg expert load reduced: 142223.03, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.128 sec, avg expert load reduced: 143635.98795180724, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.053 sec, avg expert load reduced: 145378.58479532163, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./thresholding_0_075_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
