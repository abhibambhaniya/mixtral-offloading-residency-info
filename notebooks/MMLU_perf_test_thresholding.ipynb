{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 13 21:38:56 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              76W / 700W |      4MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://people.eecs.berkeley.edu/~hendrycks/data.tar -O mmlu.tar\n",
    "# !tar -xf mmlu.tar -C mmlu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload the imported modules (e.g. get_decode_model_characterstics) every time you execute the jupyter cells, so that you don't need to restart the notebook after updating the source codes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mhqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584752/moe_offload/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "script_dir = os.getcwd()\n",
    "module_path = script_dir\n",
    "for _ in range(1):\n",
    "    module_path = os.path.abspath(os.path.join(module_path, '../'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.insert(0,module_path)\n",
    "        \n",
    "sys.path.append(\"mixtral-offloading\")\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from hqq.core.quantize import BaseQuantizeConfig\n",
    "from huggingface_hub import snapshot_download\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import trange\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers.utils import logging as hf_logging\n",
    "import time\n",
    "import gc\n",
    "from src.build_model import OffloadConfig, QuantConfig, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo2\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(quantized_model_name)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n",
    "offload_per_layer = 4\n",
    "# offload_per_layer = 5\n",
    "###############################################################\n",
    "\n",
    "num_experts = config.num_local_experts\n",
    "\n",
    "offload_config = OffloadConfig(\n",
    "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
    "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
    "    buffer_size=4,\n",
    "    offload_per_layer=offload_per_layer,\n",
    ")\n",
    "\n",
    "\n",
    "attn_config = BaseQuantizeConfig(\n",
    "    nbits=4,\n",
    "    group_size=64,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
    "\n",
    "\n",
    "ffn_config = BaseQuantizeConfig(\n",
    "    nbits=2,\n",
    "    group_size=16,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
    "\n",
    "\n",
    "# del model\n",
    "\n",
    "gc.collect\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584752/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  7.13it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"THRESHOLDING\",\n",
    "    routing_threshold=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.175 sec, avg expert load reduced: 415.18, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.159 sec, avg expert load reduced: 1290.0814814814814, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.400 sec, avg expert load reduced: 2323.8355263157896, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.383 sec, avg expert load reduced: 3235.99, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.235 sec, avg expert load reduced: 4516.954716981132, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.293 sec, avg expert load reduced: 5972.770833333333, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.364 sec, avg expert load reduced: 6864.73, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.611 sec, avg expert load reduced: 7579.29, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.391 sec, avg expert load reduced: 8315.82, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.333 sec, avg expert load reduced: 9301.127167630058, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.292 sec, avg expert load reduced: 10281.617647058823, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.169 sec, avg expert load reduced: 11009.16, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.087 sec, avg expert load reduced: 12275.251063829788, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.420 sec, avg expert load reduced: 13628.956140350878, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.236 sec, avg expert load reduced: 14567.496551724138, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.346 sec, avg expert load reduced: 16476.367724867723, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.437 sec, avg expert load reduced: 18317.261904761905, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.219 sec, avg expert load reduced: 19153.16, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.330 sec, avg expert load reduced: 20753.01935483871, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.311 sec, avg expert load reduced: 22674.28078817734, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.687 sec, avg expert load reduced: 23747.9, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.474 sec, avg expert load reduced: 24687.145454545454, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.170 sec, avg expert load reduced: 26003.555555555555, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.258 sec, avg expert load reduced: 27380.78756476684, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.167 sec, avg expert load reduced: 29449.835897435896, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.320 sec, avg expert load reduced: 31788.814814814814, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.186 sec, avg expert load reduced: 33632.3025210084, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.355 sec, avg expert load reduced: 35056.867549668874, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.300 sec, avg expert load reduced: 37594.064220183485, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.618 sec, avg expert load reduced: 40364.56481481482, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.497 sec, avg expert load reduced: 41862.436274509804, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.246 sec, avg expert load reduced: 43380.22784810127, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.100 sec, avg expert load reduced: 45119.68161434978, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.140 sec, avg expert load reduced: 46507.259541984735, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.443 sec, avg expert load reduced: 47471.74380165289, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.190 sec, avg expert load reduced: 48338.9537037037, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.228 sec, avg expert load reduced: 49344.05521472393, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.455 sec, avg expert load reduced: 50359.71428571428, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.073 sec, avg expert load reduced: 51113.271844660194, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.204 sec, avg expert load reduced: 52325.81196581197, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.148 sec, avg expert load reduced: 53511.65, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.101 sec, avg expert load reduced: 56673.62324393359, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.279 sec, avg expert load reduced: 60819.332369942196, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.461 sec, avg expert load reduced: 65834.98435754189, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.411 sec, avg expert load reduced: 70556.44117647059, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.127 sec, avg expert load reduced: 72817.73954983923, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.337 sec, avg expert load reduced: 75253.46913580247, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.516 sec, avg expert load reduced: 77528.17730496454, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.467 sec, avg expert load reduced: 84145.82790091264, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.960 sec, avg expert load reduced: 90778.07720588235, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.377 sec, avg expert load reduced: 93904.76633986928, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.204 sec, avg expert load reduced: 96438.82727272727, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:1.995 sec, avg expert load reduced: 97676.74285714286, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.228 sec, avg expert load reduced: 99274.07960199004, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.215 sec, avg expert load reduced: 100413.79, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.138 sec, avg expert load reduced: 101401.01807228915, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.065 sec, avg expert load reduced: 102612.08187134503, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./thresholding_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Ref: https://wandb.ai/byyoung3/ml-news/reports/Testing-Mixtral-8x7B-with-MMLU-and-W-B---Vmlldzo2MjI0ODAz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584752/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"THRESHOLDING\",\n",
    "    routing_threshold=0.075\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.133 sec, avg expert load reduced: 599.33, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.144 sec, avg expert load reduced: 1882.8592592592593, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.384 sec, avg expert load reduced: 3385.125, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.366 sec, avg expert load reduced: 4655.49, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.219 sec, avg expert load reduced: 6464.0037735849055, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.277 sec, avg expert load reduced: 8545.583333333334, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.343 sec, avg expert load reduced: 9841.8, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.592 sec, avg expert load reduced: 10911.43, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.373 sec, avg expert load reduced: 11974.73, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.315 sec, avg expert load reduced: 13425.71098265896, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.276 sec, avg expert load reduced: 14842.362745098038, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.155 sec, avg expert load reduced: 15900.2, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.069 sec, avg expert load reduced: 17734.73191489362, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.406 sec, avg expert load reduced: 19684.36842105263, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.225 sec, avg expert load reduced: 21048.344827586207, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.332 sec, avg expert load reduced: 23772.53439153439, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.422 sec, avg expert load reduced: 26448.73015873016, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.208 sec, avg expert load reduced: 27662.6, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.317 sec, avg expert load reduced: 29839.60322580645, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.297 sec, avg expert load reduced: 32580.935960591134, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.675 sec, avg expert load reduced: 34170.55, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.463 sec, avg expert load reduced: 35511.07878787879, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.158 sec, avg expert load reduced: 37325.32828282828, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.245 sec, avg expert load reduced: 39283.678756476686, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.155 sec, avg expert load reduced: 42194.015384615384, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.308 sec, avg expert load reduced: 45503.32962962963, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.172 sec, avg expert load reduced: 48164.6512605042, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.343 sec, avg expert load reduced: 50177.30463576159, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.288 sec, avg expert load reduced: 53805.7504587156, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.605 sec, avg expert load reduced: 57760.75925925926, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.486 sec, avg expert load reduced: 59878.936274509804, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.236 sec, avg expert load reduced: 61998.10548523207, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.092 sec, avg expert load reduced: 64366.29596412556, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.130 sec, avg expert load reduced: 66218.29770992366, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.433 sec, avg expert load reduced: 67526.17355371901, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.178 sec, avg expert load reduced: 68766.31481481482, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.217 sec, avg expert load reduced: 70162.69938650307, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.442 sec, avg expert load reduced: 71575.99107142857, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.061 sec, avg expert load reduced: 72715.7572815534, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.191 sec, avg expert load reduced: 74498.70512820513, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.139 sec, avg expert load reduced: 76275.95, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.090 sec, avg expert load reduced: 80810.83269476373, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.267 sec, avg expert load reduced: 86648.80635838151, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.447 sec, avg expert load reduced: 93716.85363128492, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.398 sec, avg expert load reduced: 100324.46078431372, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.113 sec, avg expert load reduced: 103525.31832797428, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.324 sec, avg expert load reduced: 106870.41975308642, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.502 sec, avg expert load reduced: 110083.92907801419, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.456 sec, avg expert load reduced: 119364.43350717079, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.952 sec, avg expert load reduced: 128583.79779411765, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.367 sec, avg expert load reduced: 133058.27614379086, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.193 sec, avg expert load reduced: 136668.57272727272, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./thresholding_0_075_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
