{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 16 17:37:34 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          Off | 00000000:87:00.0 Off |                    0 |\n",
      "| N/A   50C    P0             141W / 700W |  12685MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1161340      C   /593697/moe_offload/bin/python            12656MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://people.eecs.berkeley.edu/~hendrycks/data.tar -O mmlu.tar\n",
    "# !tar -xf mmlu.tar -C mmlu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload the imported modules (e.g. get_decode_model_characterstics) every time you execute the jupyter cells, so that you don't need to restart the notebook after updating the source codes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mhqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/593697/moe_offload/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "script_dir = os.getcwd()\n",
    "module_path = script_dir\n",
    "for _ in range(1):\n",
    "    module_path = os.path.abspath(os.path.join(module_path, '../'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.insert(0,module_path)\n",
    "        \n",
    "sys.path.append(\"mixtral-offloading\")\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from hqq.core.quantize import BaseQuantizeConfig\n",
    "from huggingface_hub import snapshot_download\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import trange\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers.utils import logging as hf_logging\n",
    "import time\n",
    "import gc\n",
    "from src.build_model import OffloadConfig, QuantConfig, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(quantized_model_name)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n",
    "offload_per_layer = 6\n",
    "# offload_per_layer = 5\n",
    "###############################################################\n",
    "\n",
    "num_experts = config.num_local_experts\n",
    "\n",
    "offload_config = OffloadConfig(\n",
    "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
    "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
    "    buffer_size=4,\n",
    "    offload_per_layer=offload_per_layer,\n",
    ")\n",
    "\n",
    "\n",
    "attn_config = BaseQuantizeConfig(\n",
    "    nbits=4,\n",
    "    group_size=64,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
    "\n",
    "\n",
    "ffn_config = BaseQuantizeConfig(\n",
    "    nbits=2,\n",
    "    group_size=16,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
    "\n",
    "\n",
    "# del model\n",
    "\n",
    "gc.collect\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/593697/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.51it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"TOP-K\",\n",
    "    routing_threshold=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.414 sec, avg expert load reduced: 0.0, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.494 sec, avg expert load reduced: 0.0, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.718 sec, avg expert load reduced: 0.0, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.698 sec, avg expert load reduced: 0.0, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.556 sec, avg expert load reduced: 0.0, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.615 sec, avg expert load reduced: 0.0, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.677 sec, avg expert load reduced: 0.0, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.914 sec, avg expert load reduced: 0.0, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.692 sec, avg expert load reduced: 0.0, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.646 sec, avg expert load reduced: 0.0, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.612 sec, avg expert load reduced: 0.0, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.496 sec, avg expert load reduced: 0.0, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.428 sec, avg expert load reduced: 0.0, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.746 sec, avg expert load reduced: 0.0, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.565 sec, avg expert load reduced: 0.0, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.669 sec, avg expert load reduced: 0.0, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.759 sec, avg expert load reduced: 0.0, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.539 sec, avg expert load reduced: 0.0, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.655 sec, avg expert load reduced: 0.0, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.631 sec, avg expert load reduced: 0.0, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.995 sec, avg expert load reduced: 0.0, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.741 sec, avg expert load reduced: 0.0, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.481 sec, avg expert load reduced: 0.0, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.580 sec, avg expert load reduced: 0.0, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.491 sec, avg expert load reduced: 0.0, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.639 sec, avg expert load reduced: 0.0, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.512 sec, avg expert load reduced: 0.0, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.672 sec, avg expert load reduced: 0.0, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.615 sec, avg expert load reduced: 0.0, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.922 sec, avg expert load reduced: 0.0, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.761 sec, avg expert load reduced: 0.0, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.513 sec, avg expert load reduced: 0.0, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.419 sec, avg expert load reduced: 0.0, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.475 sec, avg expert load reduced: 0.0, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.761 sec, avg expert load reduced: 0.0, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.507 sec, avg expert load reduced: 0.0, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.553 sec, avg expert load reduced: 0.0, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.775 sec, avg expert load reduced: 0.0, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.392 sec, avg expert load reduced: 0.0, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.540 sec, avg expert load reduced: 0.0, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.483 sec, avg expert load reduced: 0.0, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.442 sec, avg expert load reduced: 0.0, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.603 sec, avg expert load reduced: 0.0, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.770 sec, avg expert load reduced: 0.0, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.721 sec, avg expert load reduced: 0.0, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.457 sec, avg expert load reduced: 0.0, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.658 sec, avg expert load reduced: 0.0, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.820 sec, avg expert load reduced: 0.0, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.733 sec, avg expert load reduced: 0.0, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:2.238 sec, avg expert load reduced: 0.0, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.688 sec, avg expert load reduced: 0.0, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.523 sec, avg expert load reduced: 0.0, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:2.281 sec, avg expert load reduced: 0.0, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.540 sec, avg expert load reduced: 0.0, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.538 sec, avg expert load reduced: 0.0, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.468 sec, avg expert load reduced: 0.0, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.402 sec, avg expert load reduced: 0.0, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./top-K_6_offload_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Ref: https://wandb.ai/byyoung3/ml-news/reports/Testing-Mixtral-8x7B-with-MMLU-and-W-B---Vmlldzo2MjI0ODAz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading experts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  7.02it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_t = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"THRESHOLDING\",\n",
    "    routing_threshold=0.025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.177 sec, avg expert load reduced: 198.26, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.175 sec, avg expert load reduced: 667.9185185185186, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.416 sec, avg expert load reduced: 1209.2894736842106, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.395 sec, avg expert load reduced: 1669.03, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.249 sec, avg expert load reduced: 2313.9283018867923, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.307 sec, avg expert load reduced: 3054.6041666666665, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.376 sec, avg expert load reduced: 3492.11, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.624 sec, avg expert load reduced: 3853.13, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.403 sec, avg expert load reduced: 4222.12, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.344 sec, avg expert load reduced: 4727.606936416185, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.303 sec, avg expert load reduced: 5206.607843137255, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.182 sec, avg expert load reduced: 5551.31, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.098 sec, avg expert load reduced: 6188.659574468085, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.432 sec, avg expert load reduced: 6900.903508771929, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.251 sec, avg expert load reduced: 7388.420689655172, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.360 sec, avg expert load reduced: 8369.0291005291, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.451 sec, avg expert load reduced: 9314.86507936508, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.233 sec, avg expert load reduced: 9773.07, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.345 sec, avg expert load reduced: 10535.845161290323, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.325 sec, avg expert load reduced: 11452.413793103447, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.701 sec, avg expert load reduced: 11982.62, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.490 sec, avg expert load reduced: 12424.81212121212, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.185 sec, avg expert load reduced: 13080.38383838384, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.272 sec, avg expert load reduced: 13839.20207253886, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.181 sec, avg expert load reduced: 14925.484615384616, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.337 sec, avg expert load reduced: 16107.033333333333, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.205 sec, avg expert load reduced: 17032.0756302521, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.371 sec, avg expert load reduced: 17751.278145695363, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.318 sec, avg expert load reduced: 19020.622018348622, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.635 sec, avg expert load reduced: 20447.87962962963, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.513 sec, avg expert load reduced: 21182.38725490196, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.262 sec, avg expert load reduced: 21921.645569620254, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.116 sec, avg expert load reduced: 22779.255605381168, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.158 sec, avg expert load reduced: 23502.236641221374, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.460 sec, avg expert load reduced: 24006.586776859505, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.204 sec, avg expert load reduced: 24471.74074074074, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.243 sec, avg expert load reduced: 25004.122699386502, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.475 sec, avg expert load reduced: 25542.1875, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.091 sec, avg expert load reduced: 25919.980582524273, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.228 sec, avg expert load reduced: 26528.666666666668, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.166 sec, avg expert load reduced: 27140.35, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.119 sec, avg expert load reduced: 28762.568326947636, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.297 sec, avg expert load reduced: 30861.158959537574, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.482 sec, avg expert load reduced: 33159.06480446927, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.429 sec, avg expert load reduced: 35333.18954248366, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.143 sec, avg expert load reduced: 36396.9807073955, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.351 sec, avg expert load reduced: 37564.182098765436, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.530 sec, avg expert load reduced: 38713.26241134752, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.487 sec, avg expert load reduced: 41981.2001303781, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.982 sec, avg expert load reduced: 45273.58455882353, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.397 sec, avg expert load reduced: 46849.33006535948, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.219 sec, avg expert load reduced: 48101.15454545455, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:2.011 sec, avg expert load reduced: 48738.03265306122, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.244 sec, avg expert load reduced: 49583.835820895525, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.228 sec, avg expert load reduced: 50192.75, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.154 sec, avg expert load reduced: 50680.74698795181, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.080 sec, avg expert load reduced: 51300.67251461988, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model_t, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./thresholding_0_025_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
