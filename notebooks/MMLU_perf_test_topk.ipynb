{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 13 21:05:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:C7:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              73W / 700W |      4MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://people.eecs.berkeley.edu/~hendrycks/data.tar -O mmlu.tar\n",
    "# !tar -xf mmlu.tar -C mmlu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will reload the imported modules (e.g. get_decode_model_characterstics) every time you execute the jupyter cells, so that you don't need to restart the notebook after updating the source codes.\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mhqq_aten package not installed. HQQBackend.ATEN backend will not work unless you install the hqq_aten lib in hqq/kernels.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584564/moe_offload/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "script_dir = os.getcwd()\n",
    "module_path = script_dir\n",
    "for _ in range(1):\n",
    "    module_path = os.path.abspath(os.path.join(module_path, '../'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.insert(0,module_path)\n",
    "        \n",
    "sys.path.append(\"mixtral-offloading\")\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from hqq.core.quantize import BaseQuantizeConfig\n",
    "from huggingface_hub import snapshot_download\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import trange\n",
    "from transformers import AutoConfig, AutoTokenizer\n",
    "from transformers.utils import logging as hf_logging\n",
    "import time\n",
    "import gc\n",
    "from src.build_model import OffloadConfig, QuantConfig, build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "quantized_model_name = \"lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "state_path = \"Mixtral-8x7B-Instruct-v0.1-offloading-demo\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(quantized_model_name)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "##### Change this to 5 if you have only 12 GB of GPU VRAM #####\n",
    "offload_per_layer = 4\n",
    "# offload_per_layer = 5\n",
    "###############################################################\n",
    "\n",
    "num_experts = config.num_local_experts\n",
    "\n",
    "offload_config = OffloadConfig(\n",
    "    main_size=config.num_hidden_layers * (num_experts - offload_per_layer),\n",
    "    offload_size=config.num_hidden_layers * offload_per_layer,\n",
    "    buffer_size=4,\n",
    "    offload_per_layer=offload_per_layer,\n",
    ")\n",
    "\n",
    "\n",
    "attn_config = BaseQuantizeConfig(\n",
    "    nbits=4,\n",
    "    group_size=64,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "attn_config[\"scale_quant_params\"][\"group_size\"] = 256\n",
    "\n",
    "\n",
    "ffn_config = BaseQuantizeConfig(\n",
    "    nbits=2,\n",
    "    group_size=16,\n",
    "    quant_zero=True,\n",
    "    quant_scale=True,\n",
    ")\n",
    "quant_config = QuantConfig(ffn_config=ffn_config, attn_config=attn_config)\n",
    "\n",
    "\n",
    "# del model\n",
    "\n",
    "gc.collect\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584564/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"TOP-K\",\n",
    "    routing_threshold=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.229 sec, avg expert load reduced: 0.0, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.227 sec, avg expert load reduced: 0.0, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.442 sec, avg expert load reduced: 0.0, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.439 sec, avg expert load reduced: 0.0, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.285 sec, avg expert load reduced: 0.0, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.331 sec, avg expert load reduced: 0.0, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.400 sec, avg expert load reduced: 0.0, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.645 sec, avg expert load reduced: 0.0, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.429 sec, avg expert load reduced: 0.0, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.391 sec, avg expert load reduced: 0.0, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.354 sec, avg expert load reduced: 0.0, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.206 sec, avg expert load reduced: 0.0, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.130 sec, avg expert load reduced: 0.0, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.462 sec, avg expert load reduced: 0.0, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.283 sec, avg expert load reduced: 0.0, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.389 sec, avg expert load reduced: 0.0, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.479 sec, avg expert load reduced: 0.0, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.261 sec, avg expert load reduced: 0.0, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.371 sec, avg expert load reduced: 0.0, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.343 sec, avg expert load reduced: 0.0, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.722 sec, avg expert load reduced: 0.0, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.510 sec, avg expert load reduced: 0.0, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.202 sec, avg expert load reduced: 0.0, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.292 sec, avg expert load reduced: 0.0, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.200 sec, avg expert load reduced: 0.0, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.357 sec, avg expert load reduced: 0.0, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.218 sec, avg expert load reduced: 0.0, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.392 sec, avg expert load reduced: 0.0, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.334 sec, avg expert load reduced: 0.0, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.652 sec, avg expert load reduced: 0.0, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.531 sec, avg expert load reduced: 0.0, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.281 sec, avg expert load reduced: 0.0, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.134 sec, avg expert load reduced: 0.0, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.173 sec, avg expert load reduced: 0.0, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.477 sec, avg expert load reduced: 0.0, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.226 sec, avg expert load reduced: 0.0, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.263 sec, avg expert load reduced: 0.0, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.490 sec, avg expert load reduced: 0.0, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.104 sec, avg expert load reduced: 0.0, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.236 sec, avg expert load reduced: 0.0, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.182 sec, avg expert load reduced: 0.0, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.132 sec, avg expert load reduced: 0.0, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n",
      "Average accuracy 0.728 , Average Time:1.313 sec, avg expert load reduced: 0.0, - moral_disputes\n",
      "Starting moral_scenarios, dev size:(5, 6), Test size:(895, 6)\n",
      "Average accuracy 0.412 , Average Time:1.499 sec, avg expert load reduced: 0.0, - moral_scenarios\n",
      "Starting nutrition, dev size:(5, 6), Test size:(306, 6)\n",
      "Average accuracy 0.771 , Average Time:1.443 sec, avg expert load reduced: 0.0, - nutrition\n",
      "Starting philosophy, dev size:(5, 6), Test size:(311, 6)\n",
      "Average accuracy 0.727 , Average Time:1.158 sec, avg expert load reduced: 0.0, - philosophy\n",
      "Starting prehistory, dev size:(5, 6), Test size:(324, 6)\n",
      "Average accuracy 0.759 , Average Time:1.370 sec, avg expert load reduced: 0.0, - prehistory\n",
      "Starting professional_accounting, dev size:(5, 6), Test size:(282, 6)\n",
      "Average accuracy 0.521 , Average Time:1.548 sec, avg expert load reduced: 0.0, - professional_accounting\n",
      "Starting professional_law, dev size:(5, 6), Test size:(1534, 6)\n",
      "Average accuracy 0.501 , Average Time:2.502 sec, avg expert load reduced: 0.0, - professional_law\n",
      "Starting professional_medicine, dev size:(5, 6), Test size:(272, 6)\n",
      "Average accuracy 0.757 , Average Time:1.986 sec, avg expert load reduced: 0.0, - professional_medicine\n",
      "Starting professional_psychology, dev size:(5, 6), Test size:(612, 6)\n",
      "Average accuracy 0.714 , Average Time:1.409 sec, avg expert load reduced: 0.0, - professional_psychology\n",
      "Starting public_relations, dev size:(5, 6), Test size:(110, 6)\n",
      "Average accuracy 0.691 , Average Time:1.235 sec, avg expert load reduced: 0.0, - public_relations\n",
      "Starting security_studies, dev size:(5, 6), Test size:(245, 6)\n",
      "Average accuracy 0.710 , Average Time:2.021 sec, avg expert load reduced: 0.0, - security_studies\n",
      "Starting sociology, dev size:(5, 6), Test size:(201, 6)\n",
      "Average accuracy 0.866 , Average Time:1.261 sec, avg expert load reduced: 0.0, - sociology\n",
      "Starting us_foreign_policy, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.910 , Average Time:1.246 sec, avg expert load reduced: 0.0, - us_foreign_policy\n",
      "Starting virology, dev size:(5, 6), Test size:(166, 6)\n",
      "Average accuracy 0.518 , Average Time:1.172 sec, avg expert load reduced: 0.0, - virology\n",
      "Starting world_religions, dev size:(5, 6), Test size:(171, 6)\n",
      "Average accuracy 0.865 , Average Time:1.098 sec, avg expert load reduced: 0.0, - world_religions\n",
      "Average accuracy 0.429 - math\n",
      "Average accuracy 0.704 - health\n",
      "Average accuracy 0.597 - physics\n",
      "Average accuracy 0.817 - business\n",
      "Average accuracy 0.802 - biology\n",
      "Average accuracy 0.505 - chemistry\n",
      "Average accuracy 0.633 - computer science\n",
      "Average accuracy 0.663 - economics\n",
      "Average accuracy 0.593 - engineering\n",
      "Average accuracy 0.588 - philosophy\n",
      "Average accuracy 0.726 - other\n",
      "Average accuracy 0.789 - history\n",
      "Average accuracy 0.813 - geography\n",
      "Average accuracy 0.804 - politics\n",
      "Average accuracy 0.780 - psychology\n",
      "Average accuracy 0.819 - culture\n",
      "Average accuracy 0.539 - law\n",
      "Average accuracy 0.564 - STEM\n",
      "Average accuracy 0.610 - humanities\n",
      "Average accuracy 0.763 - social sciences\n",
      "Average accuracy 0.727 - other (business, health, misc.)\n",
      "Average accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./top-K_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Ref: https://wandb.ai/byyoung3/ml-news/reports/Testing-Mixtral-8x7B-with-MMLU-and-W-B---Vmlldzo2MjI0ODAz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/584564/moe_offload/lib/python3.10/site-packages/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
      "Loading experts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_t = build_model(\n",
    "    device=device,\n",
    "    quant_config=quant_config,\n",
    "    offload_config=offload_config,\n",
    "    state_path=state_path,\n",
    "    routing_strategy=\"THRESHOLDING\",\n",
    "    routing_threshold=0.025\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting abstract_algebra, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.340 , Average Time:1.180 sec, avg expert load reduced: 0.0, - abstract_algebra\n",
      "Starting anatomy, dev size:(5, 6), Test size:(135, 6)\n",
      "Average accuracy 0.593 , Average Time:1.191 sec, avg expert load reduced: 0.0, - anatomy\n",
      "Starting astronomy, dev size:(5, 6), Test size:(152, 6)\n",
      "Average accuracy 0.789 , Average Time:1.429 sec, avg expert load reduced: 0.0, - astronomy\n",
      "Starting business_ethics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.670 , Average Time:1.413 sec, avg expert load reduced: 0.0, - business_ethics\n",
      "Starting clinical_knowledge, dev size:(5, 6), Test size:(265, 6)\n",
      "Average accuracy 0.758 , Average Time:1.266 sec, avg expert load reduced: 0.0, - clinical_knowledge\n",
      "Starting college_biology, dev size:(5, 6), Test size:(144, 6)\n",
      "Average accuracy 0.764 , Average Time:1.323 sec, avg expert load reduced: 0.0, - college_biology\n",
      "Starting college_chemistry, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.480 , Average Time:1.393 sec, avg expert load reduced: 0.0, - college_chemistry\n",
      "Starting college_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.540 , Average Time:1.639 sec, avg expert load reduced: 0.0, - college_computer_science\n",
      "Starting college_mathematics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.390 , Average Time:1.420 sec, avg expert load reduced: 0.0, - college_mathematics\n",
      "Starting college_medicine, dev size:(5, 6), Test size:(173, 6)\n",
      "Average accuracy 0.665 , Average Time:1.365 sec, avg expert load reduced: 0.0, - college_medicine\n",
      "Starting college_physics, dev size:(5, 6), Test size:(102, 6)\n",
      "Average accuracy 0.480 , Average Time:1.323 sec, avg expert load reduced: 0.0, - college_physics\n",
      "Starting computer_security, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.720 , Average Time:1.204 sec, avg expert load reduced: 0.0, - computer_security\n",
      "Starting conceptual_physics, dev size:(5, 6), Test size:(235, 6)\n",
      "Average accuracy 0.643 , Average Time:1.120 sec, avg expert load reduced: 0.0, - conceptual_physics\n",
      "Starting econometrics, dev size:(5, 6), Test size:(114, 6)\n",
      "Average accuracy 0.456 , Average Time:1.456 sec, avg expert load reduced: 0.0, - econometrics\n",
      "Starting electrical_engineering, dev size:(5, 6), Test size:(145, 6)\n",
      "Average accuracy 0.593 , Average Time:1.271 sec, avg expert load reduced: 0.0, - electrical_engineering\n",
      "Starting elementary_mathematics, dev size:(5, 6), Test size:(378, 6)\n",
      "Average accuracy 0.458 , Average Time:1.381 sec, avg expert load reduced: 0.0, - elementary_mathematics\n",
      "Starting formal_logic, dev size:(5, 6), Test size:(126, 6)\n",
      "Average accuracy 0.516 , Average Time:1.472 sec, avg expert load reduced: 0.0, - formal_logic\n",
      "Starting global_facts, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.370 , Average Time:1.259 sec, avg expert load reduced: 0.0, - global_facts\n",
      "Starting high_school_biology, dev size:(5, 6), Test size:(310, 6)\n",
      "Average accuracy 0.819 , Average Time:1.367 sec, avg expert load reduced: 0.0, - high_school_biology\n",
      "Starting high_school_chemistry, dev size:(5, 6), Test size:(203, 6)\n",
      "Average accuracy 0.517 , Average Time:1.345 sec, avg expert load reduced: 0.0, - high_school_chemistry\n",
      "Starting high_school_computer_science, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.770 , Average Time:1.720 sec, avg expert load reduced: 0.0, - high_school_computer_science\n",
      "Starting high_school_european_history, dev size:(5, 6), Test size:(165, 6)\n",
      "Average accuracy 0.758 , Average Time:2.497 sec, avg expert load reduced: 0.0, - high_school_european_history\n",
      "Starting high_school_geography, dev size:(5, 6), Test size:(198, 6)\n",
      "Average accuracy 0.813 , Average Time:1.203 sec, avg expert load reduced: 0.0, - high_school_geography\n",
      "Starting high_school_government_and_politics, dev size:(5, 6), Test size:(193, 6)\n",
      "Average accuracy 0.933 , Average Time:1.292 sec, avg expert load reduced: 0.0, - high_school_government_and_politics\n",
      "Starting high_school_macroeconomics, dev size:(5, 6), Test size:(390, 6)\n",
      "Average accuracy 0.672 , Average Time:1.202 sec, avg expert load reduced: 0.0, - high_school_macroeconomics\n",
      "Starting high_school_mathematics, dev size:(5, 6), Test size:(270, 6)\n",
      "Average accuracy 0.315 , Average Time:1.356 sec, avg expert load reduced: 0.0, - high_school_mathematics\n",
      "Starting high_school_microeconomics, dev size:(5, 6), Test size:(238, 6)\n",
      "Average accuracy 0.748 , Average Time:1.224 sec, avg expert load reduced: 0.0, - high_school_microeconomics\n",
      "Starting high_school_physics, dev size:(5, 6), Test size:(151, 6)\n",
      "Average accuracy 0.411 , Average Time:1.389 sec, avg expert load reduced: 0.0, - high_school_physics\n",
      "Starting high_school_psychology, dev size:(5, 6), Test size:(545, 6)\n",
      "Average accuracy 0.855 , Average Time:1.334 sec, avg expert load reduced: 0.0, - high_school_psychology\n",
      "Starting high_school_statistics, dev size:(5, 6), Test size:(216, 6)\n",
      "Average accuracy 0.579 , Average Time:1.651 sec, avg expert load reduced: 0.0, - high_school_statistics\n",
      "Starting high_school_us_history, dev size:(5, 6), Test size:(204, 6)\n",
      "Average accuracy 0.828 , Average Time:2.536 sec, avg expert load reduced: 0.0, - high_school_us_history\n",
      "Starting high_school_world_history, dev size:(5, 6), Test size:(237, 6)\n",
      "Average accuracy 0.819 , Average Time:2.286 sec, avg expert load reduced: 0.0, - high_school_world_history\n",
      "Starting human_aging, dev size:(5, 6), Test size:(223, 6)\n",
      "Average accuracy 0.700 , Average Time:1.138 sec, avg expert load reduced: 0.0, - human_aging\n",
      "Starting human_sexuality, dev size:(5, 6), Test size:(131, 6)\n",
      "Average accuracy 0.748 , Average Time:1.178 sec, avg expert load reduced: 0.0, - human_sexuality\n",
      "Starting international_law, dev size:(5, 6), Test size:(121, 6)\n",
      "Average accuracy 0.818 , Average Time:1.480 sec, avg expert load reduced: 0.0, - international_law\n",
      "Starting jurisprudence, dev size:(5, 6), Test size:(108, 6)\n",
      "Average accuracy 0.769 , Average Time:1.226 sec, avg expert load reduced: 0.0, - jurisprudence\n",
      "Starting logical_fallacies, dev size:(5, 6), Test size:(163, 6)\n",
      "Average accuracy 0.761 , Average Time:1.269 sec, avg expert load reduced: 0.0, - logical_fallacies\n",
      "Starting machine_learning, dev size:(5, 6), Test size:(112, 6)\n",
      "Average accuracy 0.518 , Average Time:1.492 sec, avg expert load reduced: 0.0, - machine_learning\n",
      "Starting management, dev size:(5, 6), Test size:(103, 6)\n",
      "Average accuracy 0.786 , Average Time:1.106 sec, avg expert load reduced: 0.0, - management\n",
      "Starting marketing, dev size:(5, 6), Test size:(234, 6)\n",
      "Average accuracy 0.893 , Average Time:1.238 sec, avg expert load reduced: 0.0, - marketing\n",
      "Starting medical_genetics, dev size:(5, 6), Test size:(100, 6)\n",
      "Average accuracy 0.750 , Average Time:1.184 sec, avg expert load reduced: 0.0, - medical_genetics\n",
      "Starting miscellaneous, dev size:(5, 6), Test size:(783, 6)\n",
      "Average accuracy 0.845 , Average Time:1.137 sec, avg expert load reduced: 0.0, - miscellaneous\n",
      "Starting moral_disputes, dev size:(5, 6), Test size:(346, 6)\n"
     ]
    }
   ],
   "source": [
    "from mmlu import test_mmlu\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "test_mmlu(model_name=model_name, model_loaded=model, tokenizer=tokenizer, data_dir=\"./mmlu\", save_dir=\"./thresholding_0_025_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
